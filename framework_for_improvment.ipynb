{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# possible places to improve"
      ],
      "metadata": {
        "id": "JElvUMrxNAJn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PXnOnocMWA1",
        "outputId": "abc73065-0d09-4032-c07b-966d8408a86b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cf8265e17b0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "### =====================================================\n",
        "#train and possibly use parallel(maybe)\n",
        "### =====================================================\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "### =====================================================\n",
        "#adjust model#\n",
        "### =====================================================\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "### =====================================================\n",
        "#adjust loss function\n",
        "### =====================================================\n",
        "\n",
        "\n",
        "# ===== Deep Learning =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ===== Reproducibility =====\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### =====================================================\n",
        "# TODO: Replace with real data\n",
        "### =====================================================\n",
        "\n",
        "def load_data():\n",
        "    X = np.empty((0, 10))   #  10 Purkinje / pupil features\n",
        "    y = np.empty((0,))     #  accommodation depth\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X, y = load_data()\n",
        "\n",
        "# check\n",
        "assert X.ndim == 2\n",
        "assert y.ndim in [1, 2]\n"
      ],
      "metadata": {
        "id": "E5UmTgEDM2fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_regression(y_true, y_pred, name=\"model\"):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"[{name}] RMSE = {rmse:.4f}, R2 = {r2:.4f}\")\n",
        "    return rmse, r2"
      ],
      "metadata": {
        "id": "mdcOcUv4Nd3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NORMAL\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XqlSX_6oRkC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_baseline_model(model_type,X_train,y_train,X_test,y_test):\n",
        "\n",
        "\n",
        "    if model_type == \"linear\":\n",
        "        model, name = Pipeline([(\"scaler\", StandardScaler()), (\"reg\", Ridge(alpha=1.0))]), \"Linear / Ridge\"\n",
        "    elif model_type == \"svm\":\n",
        "        model, name = Pipeline([(\"scaler\", StandardScaler()),(\"svr\", SVR(kernel=\"rbf\", C=10.0, epsilon=0.01, gamma=\"scale\"))]), \"SVR (RBF)\"\n",
        "    elif model_type == \"tree\":\n",
        "        model, name = DecisionTreeRegressor(max_depth=5, random_state=42), \"Decision Tree\"\n",
        "    elif model_type == \"forest\":\n",
        "        model, name = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42), \"Random Forest\"\n",
        "    elif model_type == \"mlp\":\n",
        "        model, name = Pipeline([(\"scaler\", StandardScaler()),\n",
        "                             (\"mlp\", MLPRegressor(hidden_layer_sizes=(64,64), max_iter=1000))]), \"MLP\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
        "\n",
        "\n",
        "    # ===== Train & Evaluate =====\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    evaluate_regression(y_test, y_pred, name=name)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "gVW-Wuc8RjkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "B9eFVprTQyeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "def train_mlp(X_train, y_train, X_test, y_test, epochs=100):\n",
        "    train_ds = TabularDataset(X_train, y_train)\n",
        "    test_ds = TabularDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "\n",
        "    model = MLP(input_dim=X_train.shape[1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(torch.tensor(X_test, dtype=torch.float32)).numpy().squeeze()\n",
        "\n",
        "    evaluate_regression(y_test, y_pred, name=\"MLP\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "DA_6hzDKNzYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "So_bxHDQQ3WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((4, 4))\n",
        "        )\n",
        "        self.fc = nn.Linear(16 * 4 * 4, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "r0CvXwgLQ2Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "X = np.random.randn(300, 6)\n",
        "y = (\n",
        "    2.0 * X[:, 0]\n",
        "    - 1.5 * X[:, 1]\n",
        "    + 0.5 * X[:, 2] ** 2\n",
        "    + 0.1 * np.random.randn(300)\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "for m in [\"linear\", \"svm\", \"tree\", \"forest\", \"mlp\"]:\n",
        "    run_baseline_model(m, X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape, \"X_test shape:\", X_test.shape)\n",
        "print(\"y_train range:\", (y_train.min(), y_train.max()))\n",
        "print(\"y_test  range:\", (y_test.min(), y_test.max()))\n",
        "print(\"X_train mean/std:\", (X_train.mean(), X_train.std()))\n",
        "print(\"X_test  mean/std:\", (X_test.mean(), X_test.std()))\n",
        "\n",
        "print(\"y_train min/max:\", y_train.min(), y_train.max())\n",
        "print(\"y_test  min/max:\", y_test.min(), y_test.max())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOm4wq4DTFhU",
        "outputId": "0fb6fdac-73b2-4652-ac8b-b1b9b5020bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Linear / Ridge] RMSE = 0.7490, R2 = 0.9182\n",
            "[SVR (RBF)] RMSE = 0.7179, R2 = 0.9248\n",
            "[Decision Tree] RMSE = 1.2768, R2 = 0.7622\n",
            "[Random Forest] RMSE = 0.9754, R2 = 0.8612\n",
            "[MLP] RMSE = 0.2818, R2 = 0.9884\n",
            "X_train shape: (210, 6) X_test shape: (90, 6)\n",
            "y_train range: (np.float64(-5.746499945829033), np.float64(9.343694689936145))\n",
            "y_test  range: (np.float64(-6.221487734079538), np.float64(6.867591313824606))\n",
            "X_train mean/std: (np.float64(-0.028323515686789997), np.float64(0.9643740646507118))\n",
            "X_test  mean/std: (np.float64(0.019857510831474245), np.float64(1.0249922345652773))\n",
            "y_train min/max: -5.746499945829033 9.343694689936145\n",
            "y_test  min/max: -6.221487734079538 6.867591313824606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Features (X)\n",
        "\n",
        "The input variable X represents a set of low-dimensional, physically meaningful features extracted from the smart glass sensing system at each time frame. These features encode the geometric and optical characteristics of the eye, including the two-dimensional positions of Purkinje reflections (e.g., P1, P3, and P4), the pupil center location, and pupil size-related measurements. Rather than operating on raw image data, the feature representation embeds prior knowledge of ocular optics and eye physiology, effectively constraining the learning problem to a compact and interpretable input space. As a result, the model focuses on learning residual nonlinear relationships caused by individual anatomical differences, sensor placement variability, and non-ideal optical effects.\n",
        "\n",
        "Target Variable (y)\n",
        "\n",
        "The target variable y corresponds to the accommodation state associated with each observation, which may be represented by accommodation distance (e.g., in diopters), experimentally controlled focal depth, or a calibrated proxy derived from dynamic accommodation measurements. This target reflects the latent visual state that the smart glass system aims to infer in real time. By learning a mapping from observable optical features to accommodation state, the system enables continuous and non-invasive estimation of visual focus dynamics during natural viewing conditions.\n",
        "\n",
        "1️⃣ Calibration（个体校准）\n",
        "\n",
        "你可以做：\n",
        "\n",
        "每个受试者单独 fine-tune（few-shot）\n",
        "\n",
        "在 X 中加入 subject-specific bias\n",
        "\n",
        "用 linear / MLP 做 post-calibration mapping\n",
        "\n",
        "\n",
        "2️⃣ Data training（鲁棒训练）\n",
        "\n",
        "你可以做：\n",
        "\n",
        "加噪声模拟传感器抖动\n",
        "\n",
        "数据归一化（scale by pupil size）\n",
        "\n",
        "LOSO（leave-one-subject-out）评估\n",
        "\n"
      ],
      "metadata": {
        "id": "LPQ4YimHcGDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "a5dh_2ogVqSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}